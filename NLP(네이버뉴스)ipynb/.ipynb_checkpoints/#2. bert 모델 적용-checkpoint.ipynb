{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd13d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사명(csv 파일명) : 삼성전자\n",
      "몇 번째 테스트? 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at hyunwoongko/kobart and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# 남은 할일 \n",
    "# 기사 제목 끌고 와서 라벨링 해준다\n",
    "# 그 데이터 가지고 정확도를 예측한다. 이 때 사용될 건 accuracy, f1 score \n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Hannanum  # Hannanum 형태소 분석기 불러오기\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "search = input(\"회사명(csv 파일명) : \")\n",
    "num = int(input(\"몇 번째 테스트? \"))\n",
    "# csv\n",
    "df = pd.read_csv(f'csv/{search} 뉴스 제목{num}.csv',encoding=\"utf-8\")\n",
    "\n",
    "# df = pd.read_csv(f'csv/kakao_data_label.csv',encoding='cp949') # encoding='cp949'\n",
    "# KoELECTRA 모델 로드\n",
    "model_name = \"hyunwoongko/kobart\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 형태소 분석 함수\n",
    "hannanum = Hannanum()  # Hannanum 형태소 분석기 객체 생성\n",
    "def tokenize(text):\n",
    "    return hannanum.morphs(text)\n",
    "\n",
    "# df['content'] = df['title']\n",
    "\n",
    "# title 열에 대해 형태소 분석 적용\n",
    "\n",
    "df['title'] = df['title'].astype(str).apply(tokenize)\n",
    "# for i in range(df.shape[0]):\n",
    "#     df.iloc[i,1] = df.iloc[i,1].apply(tokenize)\n",
    "\n",
    "\n",
    "# 감성 분석을 위한 전처리 함수\n",
    "def preprocess(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs.to(device)\n",
    "    return inputs\n",
    "\n",
    "# 예측 함수\n",
    "def predict(inputs):\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    return probs[0].detach().cpu().numpy()\n",
    "\n",
    "# title을 예측해서 수치화시켜 sentiment으로 저장. 즉, title를 수치화 시킨 것이 sentiment\n",
    "df['sentiment'] = df['title'].apply(lambda x: predict(preprocess(' '.join(x))))\n",
    "\n",
    "# 0.5 기준으로 하면 부정확하긴 함... 정확도를 높이려면 이 부분 건들면 좋을 듯 또는 중립을 포함시키는 것도 해봐야 할 듯\n",
    "def convert_sentiment(probs):\n",
    "    if probs[0] < 0.5:\n",
    "        return 0\n",
    "    elif probs[0]>= 0.5:\n",
    "        return 1\n",
    "#     else:\n",
    "#         return '중립'\n",
    "\n",
    "# train할 label은 제목을 읽고 내가 직접 라벨링\n",
    "# test할 label은 0.5를 기준으로 sentiment가 0.5보다 크면 1, 작으면 0으로 기준 세움\n",
    "df['label'] = df['sentiment'].apply(convert_sentiment)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x[0]).tolist()\n",
    "df=round(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5badce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [삼성전자, ,, 윈도, 운영체제, 탑재한, 키오스크, 신제품, 출시]\n",
      "1                 [삼성전자, ,, 윈도우, 탑재한, ', 삼성, 키오스크', 출시]\n",
      "2     [네이처, 에, 실리, ㄴ, 삼성전자, ', 강유전체, ', 논문, 언박싱, &lt...\n",
      "3                  [기재부, ,, 넥슨, 2대주주, 등극에…삼성家, 사례, 재조명]\n",
      "4     [이건희, 가, 만들, ㄴ, ', 품질, 의, 삼성'…JY, ', 초일류, 삼성, ...\n",
      "5          [삼성家, 세, 모녀, ,, 상속세, 마련, 위하, 어, 4조원, 이상, 대출]\n",
      "6        [애플, ,, MR, 헤드셋, 전격, 공개, ..., 메타·삼성, 등, 과, 경쟁]\n",
      "7      [“TSMC, ‘2나노, 반도체’, 시범생산, 착수…, 삼성, 에, 크, ㄴ, 압박”]\n",
      "8     [\"반도체·디스플레이·AI·바이오, 에, 투, 이, 자, 역량, 집중해, 이, 야,...\n",
      "9     [팀쿡, 의, ‘원, 모으, 아, 띵’, 은, ‘비전, 프로’…‘공간컴퓨팅’, 내세...\n",
      "10                  [일본, 은, 어쩌다, 반도체, 추락, 국가, 가, 되, 었나]\n",
      "11    [삼성, 신경영, 30년, ,, 이제, 는, ', 이재용, 회장, ', 의, 시간,...\n",
      "12    [메타, 이, 이, 어, 애플·삼성, 도, 가, 세, ...', 메타버스, 헤드셋'...\n",
      "13    [', 초일류, 삼성, ', 을, 만들, ㄴ, 30년, 전, 이건희, 의, 한, 마...\n",
      "14    [40년, 전, 삼성, 제안, 에, 뒤바뀌, ㄴ, 운명…'세계, 1위, ', 오르,...\n",
      "15    [“1만대, 모두, 완판입니다”, 망, 하, ㄴ, 줄, 알, 아ㄴ데, ,, 이런일이...\n",
      "16       [삼성·LG,, \"친환경, 라운지, 열, 고, ,, 흙공, 던지, 기, 집중, \"]\n",
      "17    [외국인, 은, 반도체, ', 폭풍, 매수'…개미, 는, 2차전지, 에, ', 올,...\n",
      "18    [기업, ', 지배구조, 핵심지표, ', 준수율, 62%…SK텔레콤, 은, 100,...\n",
      "19        [RE100, 부담, 느끼, ㄴ, 기업들, 'CF100, 대안, 되, ㄹ까, ']\n",
      "20          [최태원·이재용, 회장, ,, 중국, 에, 슬그머니, 다니, 어, 오, 아다]\n",
      "21                             [고공행진, 반도체…짙어지, 는, 온실가스]\n",
      "22           [삼성, 신경영, 30년, ,, 이재용, 회장, ‘뉴, 삼성’, 에, 이목]\n",
      "23    [\", 올해, 만, 13조, ,, 폭풍, 매수, \", ..., 외, 이, ㄴ, 지갑...\n",
      "24    [\", 中, 추격, 하, 는, 신세지만\"…삼성, 엑시노스,, 부활, 의, 서막, [...\n",
      "25    [', 신경영, 선언, ', 30년, ,, 하, ㄴ, 발, 앞서, 었던, 이건희…초...\n",
      "26                [[, 글로벌, 아이, ], 머스크, 방중, 이, 남기, ㄴ, 것]\n",
      "27    [인텔, ,, 업계, 최초, ‘웨이퍼, 후, 이, 면서, 전력, 공급’…“2나노, ...\n",
      "28                             [고공행진, 반도체…짙어지, 는, 온실가스]\n",
      "29    [\", 매출, 20, %, 가, 인건비, ,, 임금, 더, 오르면…\", ', 반도체...\n",
      "30                  [\", 글로벌, TV, 사운드바, 트렌드, 는, 다다익선, \"]\n",
      "31    [인기, 없, 던, 시골, 회사, 의, 대반전…주, 가, 70, %, 폭등, 에, ...\n",
      "32                   [수익률, 치솟, 자, 뭉칫돈, 몰리, 는, 반도체, ETF]\n",
      "33                    [“파운드리, 주도권, 탈환”, 인텔, 반격, 나, 아아다]\n",
      "Name: title, dtype: object\n",
      "0     0.44\n",
      "1     0.29\n",
      "2     0.48\n",
      "3     0.33\n",
      "4     0.32\n",
      "5     0.48\n",
      "6     0.33\n",
      "7     0.29\n",
      "8     0.31\n",
      "9     0.48\n",
      "10    0.42\n",
      "11    0.41\n",
      "12    0.32\n",
      "13    0.39\n",
      "14    0.47\n",
      "15    0.26\n",
      "16    0.41\n",
      "17    0.44\n",
      "18    0.34\n",
      "19    0.64\n",
      "20    0.42\n",
      "21    0.38\n",
      "22    0.45\n",
      "23    0.49\n",
      "24    0.40\n",
      "25    0.28\n",
      "26    0.53\n",
      "27    0.33\n",
      "28    0.38\n",
      "29    0.35\n",
      "30    0.43\n",
      "31    0.42\n",
      "32    0.29\n",
      "33    0.36\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# csv 파일로 저장\n",
    "df.to_csv(f'csv/sentiment_{search}_{num}.csv', index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(df['title'])\n",
    "print(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ba575",
   "metadata": {},
   "source": [
    "# 아래는 train_set 업데이트 할 때만 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19cdf992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv\n",
    "samsung_df = pd.read_csv(f'csv/samsung_data_set.csv',encoding='cp949')\n",
    "\n",
    "\n",
    "\n",
    "# content 열에 대해 형태소 분석 적용\n",
    "df['title'] = df['title'].apply(tokenize)\n",
    "\n",
    "df['sentiment'] = df['title'].apply(lambda x: predict(preprocess(' '.join(x))))\n",
    "\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x[0]).tolist()\n",
    "df=round(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "459d7bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'csv/samsung_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv/samsung_train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CapstonStockProject\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CapstonStockProject\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CapstonStockProject\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\CapstonStockProject\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'csv/samsung_train.csv'"
     ]
    }
   ],
   "source": [
    "df.to_csv(f'csv/samsung_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313ccc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CapstonStockProject",
   "language": "python",
   "name": "capstonestockproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
