{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bd13d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "회사명(csv 파일명) : 삼성전자\n",
      "몇 번째 테스트? 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at hyunwoongko/kobart and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "# 남은 할일 \n",
    "# 기사 제목 끌고 와서 라벨링 해준다\n",
    "# 그 데이터 가지고 정확도를 예측한다. 이 때 사용될 건 accuracy, f1 score \n",
    "\n",
    "import pandas as pd\n",
    "from konlpy.tag import Hannanum  # Hannanum 형태소 분석기 불러오기\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "search = input(\"회사명(csv 파일명) : \")\n",
    "num = int(input(\"몇 번째 테스트? \"))\n",
    "# csv\n",
    "df = pd.read_csv(f'csv/{search} 뉴스 제목{num}.csv',encoding=\"utf-8\")\n",
    "\n",
    "# df = pd.read_csv(f'csv/kakao_data_label.csv',encoding='cp949') # encoding='cp949'\n",
    "# KoELECTRA 모델 로드\n",
    "model_name = \"hyunwoongko/kobart\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 형태소 분석 함수\n",
    "hannanum = Hannanum()  # Hannanum 형태소 분석기 객체 생성\n",
    "def tokenize(text):\n",
    "    return hannanum.morphs(text)\n",
    "\n",
    "# df['content'] = df['title']\n",
    "\n",
    "# title 열에 대해 형태소 분석 적용\n",
    "\n",
    "df['title'] = df['title'].astype(str).apply(tokenize)\n",
    "# for i in range(df.shape[0]):\n",
    "#     df.iloc[i,1] = df.iloc[i,1].apply(tokenize)\n",
    "\n",
    "\n",
    "# 감성 분석을 위한 전처리 함수\n",
    "def preprocess(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    inputs.to(device)\n",
    "    return inputs\n",
    "\n",
    "# 예측 함수\n",
    "def predict(inputs):\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = logits.softmax(dim=-1)\n",
    "    return probs[0].detach().cpu().numpy()\n",
    "\n",
    "# title을 예측해서 수치화시켜 sentiment으로 저장. 즉, title를 수치화 시킨 것이 sentiment\n",
    "df['sentiment'] = df['title'].apply(lambda x: predict(preprocess(' '.join(x))))\n",
    "\n",
    "# 0.5 기준으로 하면 부정확하긴 함... 정확도를 높이려면 이 부분 건들면 좋을 듯 또는 중립을 포함시키는 것도 해봐야 할 듯\n",
    "def convert_sentiment(probs):\n",
    "    if probs[0] < 0.5:\n",
    "        return 0\n",
    "    elif probs[0]>= 0.5:\n",
    "        return 1\n",
    "#     else:\n",
    "#         return '중립'\n",
    "\n",
    "# train할 label은 제목을 읽고 내가 직접 라벨링\n",
    "# test할 label은 0.5를 기준으로 sentiment가 0.5보다 크면 1, 작으면 0으로 기준 세움\n",
    "df['label'] = df['sentiment'].apply(convert_sentiment)\n",
    "df['sentiment'] = df['sentiment'].apply(lambda x: x[0]).tolist()\n",
    "df=round(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5badce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0               [삼성전자, ,, 윈도, 운영체제, 탑재한, 키오스크, 신제품, 출시]\n",
      "1                 [삼성전자, ,, 윈도우, 탑재한, ', 삼성, 키오스크', 출시]\n",
      "2     [네이처, 에, 실리, ㄴ, 삼성전자, ', 강유전체, ', 논문, 언박싱, &lt...\n",
      "3                  [기재부, ,, 넥슨, 2대주주, 등극에…삼성家, 사례, 재조명]\n",
      "4     [이건희, 가, 만들, ㄴ, ', 품질, 의, 삼성'…JY, ', 초일류, 삼성, ...\n",
      "5          [삼성家, 세, 모녀, ,, 상속세, 마련, 위하, 어, 4조원, 이상, 대출]\n",
      "6        [애플, ,, MR, 헤드셋, 전격, 공개, ..., 메타·삼성, 등, 과, 경쟁]\n",
      "7      [“TSMC, ‘2나노, 반도체’, 시범생산, 착수…, 삼성, 에, 크, ㄴ, 압박”]\n",
      "8     [\"반도체·디스플레이·AI·바이오, 에, 투, 이, 자, 역량, 집중해, 이, 야,...\n",
      "9     [팀쿡, 의, ‘원, 모으, 아, 띵’, 은, ‘비전, 프로’…‘공간컴퓨팅’, 내세...\n",
      "10                  [일본, 은, 어쩌다, 반도체, 추락, 국가, 가, 되, 었나]\n",
      "11    [삼성, 신경영, 30년, ,, 이제, 는, ', 이재용, 회장, ', 의, 시간,...\n",
      "12    [메타, 이, 이, 어, 애플·삼성, 도, 가, 세, ...', 메타버스, 헤드셋'...\n",
      "13    [', 초일류, 삼성, ', 을, 만들, ㄴ, 30년, 전, 이건희, 의, 한, 마...\n",
      "14    [40년, 전, 삼성, 제안, 에, 뒤바뀌, ㄴ, 운명…'세계, 1위, ', 오르,...\n",
      "15    [“1만대, 모두, 완판입니다”, 망, 하, ㄴ, 줄, 알, 아ㄴ데, ,, 이런일이...\n",
      "16       [삼성·LG,, \"친환경, 라운지, 열, 고, ,, 흙공, 던지, 기, 집중, \"]\n",
      "17    [외국인, 은, 반도체, ', 폭풍, 매수'…개미, 는, 2차전지, 에, ', 올,...\n",
      "18    [기업, ', 지배구조, 핵심지표, ', 준수율, 62%…SK텔레콤, 은, 100,...\n",
      "19        [RE100, 부담, 느끼, ㄴ, 기업들, 'CF100, 대안, 되, ㄹ까, ']\n",
      "20          [최태원·이재용, 회장, ,, 중국, 에, 슬그머니, 다니, 어, 오, 아다]\n",
      "21                             [고공행진, 반도체…짙어지, 는, 온실가스]\n",
      "22           [삼성, 신경영, 30년, ,, 이재용, 회장, ‘뉴, 삼성’, 에, 이목]\n",
      "23    [\", 올해, 만, 13조, ,, 폭풍, 매수, \", ..., 외, 이, ㄴ, 지갑...\n",
      "24    [\", 中, 추격, 하, 는, 신세지만\"…삼성, 엑시노스,, 부활, 의, 서막, [...\n",
      "25    [', 신경영, 선언, ', 30년, ,, 하, ㄴ, 발, 앞서, 었던, 이건희…초...\n",
      "26                [[, 글로벌, 아이, ], 머스크, 방중, 이, 남기, ㄴ, 것]\n",
      "27    [인텔, ,, 업계, 최초, ‘웨이퍼, 후, 이, 면서, 전력, 공급’…“2나노, ...\n",
      "28                             [고공행진, 반도체…짙어지, 는, 온실가스]\n",
      "29    [\", 매출, 20, %, 가, 인건비, ,, 임금, 더, 오르면…\", ', 반도체...\n",
      "30                  [\", 글로벌, TV, 사운드바, 트렌드, 는, 다다익선, \"]\n",
      "31    [인기, 없, 던, 시골, 회사, 의, 대반전…주, 가, 70, %, 폭등, 에, ...\n",
      "32                   [수익률, 치솟, 자, 뭉칫돈, 몰리, 는, 반도체, ETF]\n",
      "33                    [“파운드리, 주도권, 탈환”, 인텔, 반격, 나, 아아다]\n",
      "Name: title, dtype: object\n",
      "0     0.44\n",
      "1     0.29\n",
      "2     0.48\n",
      "3     0.33\n",
      "4     0.32\n",
      "5     0.48\n",
      "6     0.33\n",
      "7     0.29\n",
      "8     0.31\n",
      "9     0.48\n",
      "10    0.42\n",
      "11    0.41\n",
      "12    0.32\n",
      "13    0.39\n",
      "14    0.47\n",
      "15    0.26\n",
      "16    0.41\n",
      "17    0.44\n",
      "18    0.34\n",
      "19    0.64\n",
      "20    0.42\n",
      "21    0.38\n",
      "22    0.45\n",
      "23    0.49\n",
      "24    0.40\n",
      "25    0.28\n",
      "26    0.53\n",
      "27    0.33\n",
      "28    0.38\n",
      "29    0.35\n",
      "30    0.43\n",
      "31    0.42\n",
      "32    0.29\n",
      "33    0.36\n",
      "Name: sentiment, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# csv 파일로 저장\n",
    "df.to_csv(f'csv/sentiment_{search}_{num}.csv', index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(df['title'])\n",
    "print(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b2f086",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313ccc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CapstonStockProject",
   "language": "python",
   "name": "capstonestockproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
